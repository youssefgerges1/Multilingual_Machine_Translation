{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MarianMT by Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentencepiece installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "print(\"sentencepiece installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MarianMT for Arabic-to-English Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my mom.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer # type: ignore\n",
    "\n",
    "# Load the MarianMT model and tokenizer for Arabic-to-English translation\n",
    "model_name = 'Helsinki-NLP/opus-mt-ar-en'\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ask the user to input Arabic text\n",
    "input_text = input(\"Please enter Arabic text for translation: \") # انا بحب امي \n",
    "\n",
    "# Tokenize the input text\n",
    "tokenized_input = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Generate the translation\n",
    "translated_tokens = model.generate(**tokenized_input)\n",
    "\n",
    "# Decode the translated text\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* M2M-100 by Facebook AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer # type: ignore\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"facebook/m2m100_418M\"  # or use m2m100_1.2B for a larger model\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Set the source and target languages\n",
    "source_lang = \"fr\"  # French\n",
    "target_lang = \"en\"  # English\n",
    "\n",
    "# Input text in the source language\n",
    "input_text = input(\"Please enter French text for translation: \") # Je suis étudiant\n",
    "\n",
    "# Tokenize input and generate translation\n",
    "tokenizer.src_lang = source_lang\n",
    "encoded_input = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate translation\n",
    "generated_tokens = model.generate(**encoded_input, forced_bos_token_id=tokenizer.get_lang_id(target_lang))\n",
    "\n",
    "# Decode the translated text\n",
    "translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Japanese to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\On_The_Fly_Project\\new_venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese food is delicious.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer # type: ignore\n",
    "\n",
    "# Load the MarianMT model and tokenizer for Japanese-to-English translation\n",
    "model_name = 'Helsinki-NLP/opus-mt-ja-en'  # Model for Japanese to English\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ask the user to input Japanese text\n",
    "input_text = input(\"Please enter Japanese text for translation: \") # 日本の食べ物は美味しいです。\n",
    "\n",
    "\n",
    "# Tokenize the input text\n",
    "tokenized_input = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Generate the translation\n",
    "translated_tokens = model.generate(**tokenized_input)\n",
    "\n",
    "# Decode the translated text\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: ar\n",
      "Translated text: Peace to you.\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer # type: ignore\n",
    "from langdetect import detect, DetectorFactory  # type: ignore # Import language detection library\n",
    "\n",
    "# Set seed for language detection stability\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"facebook/m2m100_418M\"\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Set the target language\n",
    "target_lang = \"en\"  # English\n",
    "\n",
    "# Input text\n",
    "input_text = input(\"Please enter text for translation: \")\n",
    "\n",
    "# Detect the language of the input text\n",
    "detected_lang = detect(input_text)\n",
    "print(f\"Detected language: {detected_lang}\")\n",
    "\n",
    "# Check if the detected language is not English\n",
    "if detected_lang == target_lang:\n",
    "    print(\"The text is already in English.\")\n",
    "    translated_text = input_text  # No translation needed\n",
    "else:\n",
    "    # Tokenize the input and generate translation\n",
    "    tokenizer.src_lang = detected_lang  # Set the detected source language\n",
    "    encoded_input = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(**encoded_input, forced_bos_token_id=tokenizer.get_lang_id(target_lang))\n",
    "\n",
    "    # Decode the translated text\n",
    "    translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the translated text\n",
    "print(\"Translated text:\", translated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_venv)",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
